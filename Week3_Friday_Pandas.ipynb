{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pandas_white.svg\" alt=\"pandas\" width=\"500\"/>\n",
    "pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language.  pandas aims to be the fundamental high-level building block for doing practical, real world data analysis in Python.\n",
    "\n",
    "## Highlights\n",
    "* A fast and efficient DataFrame object for data manipulation with integrated indexing;\n",
    "\n",
    "* Tools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format;\n",
    "\n",
    "* Intelligent data alignment and integrated handling of missing data: gain automatic label-based alignment in computations and easily manipulate messy data into an orderly form;\n",
    "\n",
    "* Flexible reshaping and pivoting of data sets;\n",
    "\n",
    "* Intelligent label-based slicing, fancy indexing, and subsetting of large data sets;\n",
    "\n",
    "* Columns can be inserted and deleted from data structures for size mutability;\n",
    "\n",
    "* Aggregating or transforming data with a powerful group by engine allowing split-apply-combine operations on data sets;\n",
    "\n",
    "* High performance merging and joining of data sets;\n",
    "\n",
    "* Time series-functionality: date range generation and frequency conversion.\n",
    "\n",
    "* Python with pandas is in use in a wide variety of academic and commercial domains, including Finance, Neuroscience, Economics, Statistics, Advertising, Web Analytics, and more.\n",
    "\n",
    "## Installation Instructions:\n",
    "Go to your terminal / bash / commandline / powershell and enter in the following command\n",
    "\n",
    "--> `pip install pandas`\n",
    "\n",
    "It is common practice to import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Types\n",
    "Pandas essentially has three data types of its own (remember data types are like list, dict, and str)\n",
    "1. DataFrame\n",
    "2. Series\n",
    "3. Panel\n",
    "\n",
    "We will be focusing on DataFrames and Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a DataFrame and Series\n",
    "\n",
    "DataFrames are the primary pandas data structure.  They are size-mutable and cant potentially contain heterogeneous tabular data.  The DataFrame is a data type that takes on the basic structure of a two-dimensional table containing rows and columns.  This is the same structure that we all are familiar with because we have seen it several times in MS Excel. \n",
    "\n",
    "In the image below is a visualization of the anatomy of a DataFrame.  The columns are identified by column labels that run atop of the columns and the rows are identified by index labels that from top to bottom along the left-hand side of the rows.  The index is the way a DataFrame labels rows.  \n",
    "\n",
    "The columns are also known as Axis 1/columns or while the index are also known as Axis 0/index.  \n",
    "Missing values with a DataFrame are noted by `NaN` (Not a number). \n",
    "\n",
    "Truncated Data is noted by elipsis (when there are many rows or columns of data, pandas by default with reduce what you are able to display on the screen).\n",
    "\n",
    "A Series is simply defined as a column thus in reality the DataFrame is a composite of Series.\n",
    "\n",
    "<img src=\"dataframe_anatomy.png\" alt=\"pandas\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames\n",
    "Documentation: [Pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "DataFrames can be defined several different ways, either via python data types or using files such as csv or excel.  We demonstrate each way below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame with a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\n",
    "                ['Larry',2,3,4],\n",
    "                ['Matt',6,7,8], \n",
    "                ['Kass', 9, 10, 11], \n",
    "                ['Ben', 12, 13,  14]\n",
    "            ]\n",
    "bubbles_n_balls = pd.DataFrame(data_list, columns=['name','bubbles', 'songs', 'balls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles_n_balls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame with a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "             'name':['Larry','Matt','Kass', 'Molly'],\n",
    "             'apples':[14, 15, 16, 17],\n",
    "             'book_id': [123, 456, 789, 101],\n",
    "            }\n",
    "name_apples_bookid = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_apples_bookid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the dimensions of a DataFrame\n",
    "It is possible to determine the shape of a DataFrame (ie the number of rows and columns).  You use the `pd.DataFrame.shape` attribute.  It returns a tuple with (number of rows, number of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_apples_bookid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_apples_bookid) #provides the number of rows in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a glimpse of the data\n",
    "You can use the pd.DataFrame.head() and pd.DataFrame.tail() methods to get a glimpse of the first or last 5 rows within a DataFrame, respectively.  The methods do take an argument for which you can select the number of rows you would like to see, by default it is set to 5 if you don't specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_apples_bookid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_apples_bookid.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from a flat files\n",
    "Documentation: [Type of flat files accepted by Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)\n",
    "It is possible to read data into Pandas from flat files such as csv or excel.  DataFrame data type has methods attached to them. `pd.DataFram.read_csv` takes the path of a csv file and converts it into a DataFrame object.  `pd.DataFrame.read_excel` takes the path of a excel file and converts it into a DataFrame object.\n",
    "\n",
    "Documentation: [Pandas.DataFrame.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.read_csv.html)\n",
    "\n",
    "Documentation: [Pandas.DataFrame.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.read_excel.html)\n",
    "- requires python package `pip install openpyxl`\n",
    "\n",
    "## Reading data from Flat Files\n",
    "Documentation: [Pandas.DataFrame.read_table](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.read_table.html)\n",
    "\n",
    "You should always manually inspect your data before reading it into pandas.  You should take note of how it is structured into columns and rows.\n",
    "\n",
    "### Writing DataFrame to File\n",
    "Documentation: [Pandas.DataFrame.to_csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n",
    "\n",
    "Documentation: [Pandas.DataFrame.to_excel](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html)\n",
    "- requires python package `pip install openpyxl`\n",
    "\n",
    "Documentation: [Pandas.ExcelWriter](https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html)\n",
    "- can create multiple sheets within a workbook\n",
    "- requires python package `openpyxl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write CSV file from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_apples_bookid.to_csv('name_apples_bookid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('name_apples_bookid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_apples_bookid.to_excel('name_apples_bookid.xlsx', engine='openpyxl', index=False)\n",
    "excel = pd.read_excel('name_apples_bookid.xlsx', engine='openpyxl')\n",
    "excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a table file\n",
    "Always look at your files before trying to import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unames = ['category', 'book_id', 'book_name', 'rank', 'sales', 'type', 'sold_out', 'best_seller']\n",
    "books = pd.read_table('book_categories.txt', sep='--', names = unames, engine='python', header=0)\n",
    "\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series\n",
    "Documentation: [Pandas.Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)\n",
    "The Series data type is a pandas representation of a column.  This data type has specific methods that allow you to manipulate the data within the Series.  There are also attributes that provide information about state of the series.  We will discuss both methods and attributes later on.  The values with a series are generally all the same type, for instance strings, integers, floats, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Series with a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_list = ['monkey','kangaroo','horse','cat']\n",
    "series_list_1 = pd.Series(data=animals_list)\n",
    "series_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list_2 = pd.Series(animals_list, index=['a','b','c','d'])\n",
    "series_list_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Series with a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_dict = {'a':'monkey', 'b':'kangaroo', 'c':'horse', 'd':'cat'}\n",
    "series_dict = pd.Series(data=animals_dict)\n",
    "series_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict + '_tail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_one_to_ten = pd.Series([1,2,3,4,5,6,7,8,9,10, None])\n",
    "print('Multiply \\n', series_one_to_ten * 10, '\\n\\n')\n",
    "print('floor division \\n', series_one_to_ten // 2.5, '\\n\\n')\n",
    "print('modulus \\n', series_one_to_ten % 2, '\\n\\n')\n",
    "print('greater_than \\n', series_one_to_ten > 5, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtypes\n",
    "Columns within a DataFrame(ie Series) can be composed of different data types.  The type determines which methods are available to manipulate the column. below are a few of them\n",
    "`object` which represents strings or when mixed values (A column contains many types of values)\n",
    "`int64` which represents integers\n",
    "`float64` which represents floats\n",
    "`bool` which represents bool\n",
    "`datetime[ns]` which represents data and time\n",
    "`category` which represents a categorical value\n",
    "\n",
    "* float – The NumPy float type, which supports missing values\n",
    "* int – The NumPy integer type, which does not support missing values\n",
    "* 'Int64' – pandas nullable integer type\n",
    "* object – The NumPy type for storing strings (and mixed types)\n",
    "* 'category' – pandas categorical type, which does support missing values\n",
    "* bool – The NumPy Boolean type, which does not support missing values (None becomes False, np.nan becomes True)\n",
    "* 'boolean' – pandas nullable Boolean type\n",
    "* datetime64[ns] – The NumPy date type, which does support missing values (NaT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access dtypes from DataFrame and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_apples_bookid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Pair Programming \n",
    "The data file `supermarket_sales.csv` for this exercise is located in the Canvas `Files` tab within the Module 2 Folder and finally in Week3 Folder.\n",
    "\n",
    "#### Question 1\n",
    "1. Read the `supermarket_sales.csv` file into Pandas and assign it to a variable named `df`\n",
    "\n",
    "#### Question 2\n",
    "2. Is `df` a Series or DataFrame?\n",
    "\n",
    "#### Question 3\n",
    "3. How many columns and rows are within the `df`?\n",
    "\n",
    "#### Question 4\n",
    "4. How many of each dtype is contained within the `df` ?\n",
    "\n",
    "#### Question 5\n",
    "5. Write `df` to an excel file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
